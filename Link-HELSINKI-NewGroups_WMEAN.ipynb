{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tee yleiset muuttujanimet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from pyproj import CRS\n",
    "from shapely import geometry, ops\n",
    "from scipy.sparse.csgraph import connected_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "network2 = gpd.read_file(\"C:/data/L3Pilot/Katuverkko/Helsinki/hki_link_liikennemääräkartta2019/hki_liikennemaarat_2019_linkkikartta_3067_geomfix.shp\") \n",
    "#network2 = gpd.read_file(\"C:/data/L3Pilot/Katuverkko/Helsinki/hki_link_liikennemääräkartta2019/hki_liikennemaarat_2019_linkkikartta_3067_geomfix_vclean.shp\")\n",
    "#network2 = gpd.read_file(\"C:/data/L3Pilot/Katuverkko/Helsinki/hki_link_liikennemääräkartta2019/test/Kehä1.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "collist = list(network2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = gpd.GeoDataFrame(network2, columns=collist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "network[\"KATULUOKKA\"] = network[\"KL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = network.groupby(\"KATU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternative katulist\n",
    "katulist = list(network2[\"KATU\"])\n",
    "my_set = set(katulist)\n",
    "uniquekadut = list(my_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "463"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uniquekadut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "\n",
    "testilista = []\n",
    "mergelist = []\n",
    "touchingbufslist2 = []\n",
    "bufdflist2 = []\n",
    "homogeeniset_linkit = gpd.GeoDataFrame()\n",
    "mergetest = gpd.GeoDataFrame()\n",
    "\n",
    "#for i in katulist: #Iterate over streets\n",
    "for i in uniquekadut:\n",
    "    grp = grouped.get_group(i)\n",
    "    KLgrouped = grp.groupby(\"KL\") #Group by road class\n",
    "    \n",
    "    #Iterate over classes in street\n",
    "    for key, y in KLgrouped:\n",
    "        KLgrp = KLgrouped.get_group(key)\n",
    "        #Dissolve road sections that are of the same class in the same street\n",
    "        dissolved = KLgrp.dissolve(by=\"KL\") \n",
    "        dissolved = dissolved.reset_index()\n",
    "        \n",
    "        #Select sections which are not multilinestring. They can be added to main GDF.\n",
    "        if str(type(dissolved.iloc[0, 1])) != \"<class 'shapely.geometry.multilinestring.MultiLineString'>\": \n",
    "            homogeeniset_linkit = homogeeniset_linkit.append(dissolved.iloc[0])\n",
    "        \n",
    "        #Select sections constisting of multilinestrings. These sections are not next to each other, and must be made separate for the main GDF\n",
    "        elif str(type(dissolved.iloc[0, 1])) == \"<class 'shapely.geometry.multilinestring.MultiLineString'>\": \n",
    "            merge = ops.linemerge(dissolved.iloc[0, 1]) #now have the n. of continuous pieces as multilinestring object. Must be merged to join otherwise separate but connected lines.\n",
    "            mergelist.append(merge)\n",
    "            \n",
    "       \n",
    "                #BUFFERS --------- Buffers must be created around the seperate sections selected above. \n",
    "                #This is due to links in Helsinki network not always being spatially connected in the shape file (difference of 0.1-2m usually, \n",
    "                #even though they represent roads connected in reality. Buffers are used to bridge these links.            \n",
    "           \n",
    "        #Select sections merged to multilinestrings\n",
    "            if str(type(merge)) == \"<class 'shapely.geometry.multilinestring.MultiLineString'>\": \n",
    "                dissolved3 = gpd.GeoDataFrame() #Create GDF to which we will collect these as seperate sections\n",
    "                bufdf = gpd.GeoDataFrame() #Create GDF to which we will collect buffers of the seperate sections\n",
    "                buflist = []\n",
    "                for b in range(0, (len(merge))): #Create enough rows to accommodate all sections\n",
    "                    dissolved3 = dissolved3.append(dissolved.iloc[0])\n",
    "                \n",
    "                #Put merge geometry in dissolved3\n",
    "                for x in range(0, len(dissolved3)): \n",
    "                    dissolved3[\"geometry\"].iloc[x] = merge[x]\n",
    "                    \n",
    "                dissolved3 = dissolved3.reset_index()\n",
    "                testilista.append(dissolved3)\n",
    "                \n",
    "                #Create buffers for all seperated links\n",
    "                for z in range(0, len(dissolved3)): \n",
    "                    buf = dissolved3[\"geometry\"].iloc[z].buffer(8) #<---------ADJUST BUFFER SIZE HERE-------------\n",
    "                    buflist.append(buf) #Add buffers to a list\n",
    "                \n",
    "                dissolved3 = dissolved3.drop([\"index\"], axis=\"columns\") #Remove index column from dissolved3\n",
    "                bufdf[\"geometry\"] = buflist #Add contents of buflist to bufdf \n",
    "                bufdf.reset_index()\n",
    "                bufdfseries =  bufdf[\"geometry\"]\n",
    "                bufdflist2.append(bufdf)\n",
    "                \n",
    "                \n",
    "                #Check which buffers overlap. These are assigned a group value and they represent continuous sections\n",
    "                overlap_matrix = bufdfseries.apply(lambda x: bufdfseries.overlaps(x)).values.astype(int)\n",
    "                connected_components(overlap_matrix)\n",
    "                n, ids = connected_components(overlap_matrix)\n",
    "                touchingbufs = gpd.GeoDataFrame({'geometry': bufdfseries, 'group': ids})\n",
    "                touchingbufslist2.append(touchingbufs)\n",
    "                                                             \n",
    "                               \n",
    "                # Join with previously merged sections\n",
    "                bufjoin = gpd.sjoin(dissolved3, touchingbufs, how=\"left\", op=\"within\") #Spatially join links (lines) with buffers\n",
    "                bufjoin = bufjoin.reset_index()\n",
    "                bufjoinfinal = bufjoin.dissolve(by=\"group\") #Dissolve by BufferID\n",
    "                bufjoinfinal = bufjoinfinal.reset_index()\n",
    "                \n",
    "\n",
    "                for n in range(0, len(bufjoin)): #Add links that were not within buffers\n",
    "                    if pd.isna(bufjoin[\"group\"].loc[n]):\n",
    "                        bufjoinfinal = bufjoinfinal.append(bufjoin.iloc[n])\n",
    "                \n",
    "                for q in range(0, len(bufjoinfinal)):\n",
    "                    homogeeniset_linkit = homogeeniset_linkit.append(bufjoinfinal.iloc[q]) # append final links to main GDF\n",
    "\n",
    "            else: # Any other sections need no attention and can be passed to the main GDF\n",
    "                dissolved4 = gpd.GeoDataFrame()\n",
    "                dissolved4 = dissolved4.append(dissolved.iloc[0])\n",
    "                dissolved4[\"geometry\"].iloc[0] = merge\n",
    "                homogeeniset_linkit = homogeeniset_linkit.append(dissolved4.iloc[0])\n",
    "        \n",
    "\n",
    "#homogeeniset_linkit = homogeeniset_linkit.drop([\"level_0\"], axis=\"columns\")\n",
    "homogeeniset_linkit = homogeeniset_linkit.reset_index()\n",
    "homogeeniset_linkit.crs = CRS.from_epsg(3067)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergelistnr = []\n",
    "for i in range(0, len(mergelist)):\n",
    "    if str(type(mergelist[i])) == \"<class 'shapely.geometry.multilinestring.MultiLineString'>\": \n",
    "        mergelistnr.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unnecessary columns\n",
    "homogeeniset_linkit = homogeeniset_linkit.drop([\"HA\", \"PA\", \"KA\", \"RA\", \"LA\", \"MP\", \"RV\", \"AUTOT\", \"pituus\", \"ID_NEW\", \"index\", \"index_right\", \"SY KAVL+RV\"], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating weighted mean of KVL for the continuous links:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Link identifier\n",
    "homogeeniset_linkit[\"H_ID\"] = list(range(0, len(homogeeniset_linkit)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spatial join between the continuous links we just created and the original link network\n",
    "join = gpd.sjoin(homogeeniset_linkit, network2, how=\"left\", op=\"contains\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "joingrouped = join.groupby(by=\"H_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "grplist = []\n",
    "for i in range(0, len(joingrouped)):\n",
    "    grp = joingrouped.get_group(i)\n",
    "    grp = grp.reset_index()\n",
    "    kvlXpituus = []\n",
    "    for j in range(0, len(grp)):\n",
    "        kvlXpituus.append(grp.loc[j][\"SY KAVL+RV\"]*grp.loc[j][\"pituus\"])\n",
    "    grp[\"kvlXpituus\"] = kvlXpituus\n",
    "    weightsum = sum(grp[\"pituus\"])\n",
    "    kvlsum = sum(grp[\"kvlXpituus\"])\n",
    "    weightedaverage = kvlsum/weightsum\n",
    "    wmeangrpcol = list((np.repeat(weightedaverage, len(grp))))\n",
    "    grp[\"WMEAN_KVL\"] = wmeangrpcol\n",
    "    grplist.append(grp)\n",
    "    #weightedaveragelist.append(wmeangrpcol)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "grpwmean = pd.concat(grplist)\n",
    "grpwmean = grpwmean.drop([\"kvlXpituus\", \"KATU_right\", \"index\", \"pituus\", \"KL_left\", \"KL_right\", \"LVUOSI_left\", \"linkki_left\", \"index_right\", \"linkki_right\", \"LVUOSI_right\"], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['level_0', 'KATU_left', 'KATULUOKKA', 'geometry', 'group', 'H_ID', 'HA',\n",
       "       'PA', 'KA', 'RA', 'LA', 'MP', 'RV', 'AUTOT', 'SY KAVL+RV', 'ID_NEW',\n",
       "       'WMEAN_KVL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grpwmean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates mean KVL for continuous links\n",
    "finaldissolve1 = grpwmean.dissolve(by='H_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldissolve1.crs = CRS.from_epsg(3067)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "579"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(finaldissolve1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldissolve1[\"pitklink_pituus\"] = finaldissolve1.geometry.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "homogeeniset_linkit.crs = CRS.from_epsg(3067)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldissolve1.crs = CRS.from_epsg(3067)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldissolve1 = finaldissolve1.drop([\"level_0\"], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_names = {'KATULUOKKA': 'Type', 'KATU_left': 'Section', 'H_ID': 'ID', \"pitklink_pituus\": \"Length\"}\n",
    "\n",
    "#finaldissolve1 = finaldissolve1.rename(columns=new_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['geometry', 'KATU_left', 'KATULUOKKA', 'group', 'HA', 'PA', 'KA', 'RA',\n",
       "       'LA', 'MP', 'RV', 'AUTOT', 'SY KAVL+RV', 'ID_NEW', 'WMEAN_KVL',\n",
       "       'pitklink_pituus'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldissolve1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldissolve1.to_file(\"C:/data/L3Pilot/Katuverkko/Helsinki/hki_link_liikennemääräkartta2019/finalproduct_newgroups_orig_wmean.shp\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "finaldissolve1 = finaldissolve1.drop([\"geometry\", \"HA\", \"ID_NEW\", \"group\", \"PA\", \"KA\", \"RA\", \"LA\", \"MP\", \"RV\", \"AUTOT\", \"SY KAVL+RV\"], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "finaldissolve1.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "finaldissolve1[\"Years\"] = 5"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "finaldissolve1.to_csv(\"C:/data/L3Pilot/Katuverkko/Helsinki/hki_link_liikennemääräkartta2019/finalproduct_newgroups_orig_wmean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nulldissolve.to_csv(\"C:/data/L3Pilot/Katuverkko/Helsinki/hki_link_liikennemääräkartta2019/nulldissolve.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finaldissolve1.to_file(\"C:/data/L3Pilot/Katuverkko/Helsinki/hki_link_liikennemääräkartta2019/finaldissolve.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nulldissolve.to_file(\"C:/data/L3Pilot/Katuverkko/Helsinki/hki_link_liikennemääräkartta2019/nulldissolve2.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#homogeeniset_linkit.to_file(\"C:/data/L3Pilot/Katuverkko/Helsinki/hki_link_liikennemääräkartta2019/homogeeniset_linkit_mergetest_connectionsfixed.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#homogeeniset_linkit.to_csv(\"C:/data/L3Pilot/Katuverkko/Helsinki/hki_link_liikennemääräkartta2019/homogeeniset_linkit_mergetest_connectionsfixed.csv\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "touchingbufslist = [] #Here we will collect the information concerning what buffers a buffer touches\n",
    "                excesslist = [] \n",
    "                \n",
    "\n",
    "                touchingbufs = touchingbufs.reset_index()\n",
    "                touchingbufs[\"startstop\"] = touchingbufslist #Add intersecting buffer ID to GDF which contains the buffers\n",
    "                \n",
    "                #Give running ID-Values to buffers. These will be used to dissolve continuous sections.\n",
    "                slist = []\n",
    "                idlist = []\n",
    "                for k in range(0, len(touchingbufs)):\n",
    "                    if touchingbufs[\"startstop\"].iloc[k] == \"s\":\n",
    "                        slist.append(1)\n",
    "                        idlist.append(sum(slist))\n",
    "                    elif touchingbufs[\"startstop\"].iloc[k] == \"fb\":\n",
    "                        idlist.append(sum(slist))\n",
    "                    elif touchingbufs[\"startstop\"].iloc[k] == \"b\":\n",
    "                        idlist.append(sum(slist))\n",
    "                        #slist.append(1)\n",
    "                    elif touchingbufs[\"startstop\"].iloc[k] == \"own\":\n",
    "                        slist.append(1)\n",
    "                        idlist.append(sum(slist))\n",
    "                        test = sum(slist)\n",
    "                        \n",
    "                \n",
    "                if len(touchingbufs) > 0:\n",
    "                    touchingbufs[\"dissolve\"] = idlist\n",
    "                    touchingbufs[\"BufID\"] = idlist\n",
    "                    touchingbufs[\"BufID2\"] = idlist\n",
    "                    touchingbufslist2.append(touchingbufs)\n",
    "\n",
    "                    \n",
    "                    tdissolve = touchingbufs.dissolve(by=\"dissolve\") #Dissolve buffers that touch by the intersecting buffer ID\n",
    "                if len(tdissolve) > 0: #If tdissolve contains something, add it to maxidissolve GDF\n",
    "                    maxidissolve = maxidissolve.append(tdissolve)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
