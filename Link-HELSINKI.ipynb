{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tee yleiset muuttujanimet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from pyproj import CRS\n",
    "from shapely import geometry, ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "network2 = gpd.read_file(\"C:/data/L3Pilot/Katuverkko/Helsinki/hki_link_liikennemääräkartta2019/hki_liikennemaarat_2019_linkkikartta_3067_geomfix.shp\") \n",
    "#network2 = gpd.read_file(\"C:/data/L3Pilot/Katuverkko/Helsinki/hki_link_liikennemääräkartta2019/test/Kehä1.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "collist = list(network2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = gpd.GeoDataFrame(network2, columns=collist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "network[\"KATULUOKKA\"] = network[\"KL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = network.groupby(\"KATU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternative katulist\n",
    "katulist = list(network2[\"KATU\"])\n",
    "my_set = set(katulist)\n",
    "uniquekadut = list(my_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "463"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uniquekadut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "testilista = []\n",
    "homogeeniset_linkit = gpd.GeoDataFrame()\n",
    "mergetest = gpd.GeoDataFrame()\n",
    "\n",
    "#for i in katulist: #Iterate over streets\n",
    "for i in uniquekadut:\n",
    "    grp = grouped.get_group(i)\n",
    "    KLgrouped = grp.groupby(\"KL\") #Group by road class\n",
    "    \n",
    "    #Iterate over classes in street\n",
    "    for key, y in KLgrouped:\n",
    "        KLgrp = KLgrouped.get_group(key)\n",
    "        #Dissolve road sections that are of the same class in the same street\n",
    "        dissolved = KLgrp.dissolve(by=\"KL\") \n",
    "        dissolved = dissolved.reset_index()\n",
    "        \n",
    "        #Select sections which are not multilinestring. They can be added to main GDF.\n",
    "        if str(type(dissolved.iloc[0, 1])) != \"<class 'shapely.geometry.multilinestring.MultiLineString'>\": \n",
    "            homogeeniset_linkit = homogeeniset_linkit.append(dissolved.iloc[0])\n",
    "        \n",
    "        #Select sections constisting of multilinestrings. These sections are not next to each other, and must be made separate for the main GDF\n",
    "        elif str(type(dissolved.iloc[0, 1])) == \"<class 'shapely.geometry.multilinestring.MultiLineString'>\": \n",
    "            merge = ops.linemerge(dissolved.iloc[0, 1]) #now have the n. of continuous pieces as multilinestring object. Must be merged to join otherwise separate but connected lines.\n",
    "            \n",
    "            #Select sections merged to multilinestrings\n",
    "            if str(type(merge)) == \"<class 'shapely.geometry.multilinestring.MultiLineString'>\": \n",
    "                dissolved3 = gpd.GeoDataFrame() #Create GDF to which we will collect these as seperate sections\n",
    "                bufdf = gpd.GeoDataFrame() #Create GDF to which we will collect buffers of the seperate sections\n",
    "                buflist = []\n",
    "                for b in range(0, (len(merge))): #Create enough rows to accommodate all sections\n",
    "                    dissolved3 = dissolved3.append(dissolved.iloc[0])\n",
    "                \n",
    "                #Replace old geometry with seperate sections\n",
    "                for x in range(0, len(dissolved3)): \n",
    "                    dissolved3[\"geometry\"].iloc[x] = merge[x]\n",
    "                    \n",
    "                dissolved3 = dissolved3.reset_index()\n",
    " \n",
    "                #BUFFERS --------- Buffers must be created around the seperate sections selected above. \n",
    "                #This is due to links in Helsinki network not always being spatially connected in the shape file (difference of 0.1-2m usually, \n",
    "                #even though they represent roads connected in reality. Buffers are used to bridge these links.\n",
    "                \n",
    "                #Create buffers for all seperated links\n",
    "                for z in range(0, len(dissolved3)): \n",
    "                    buf = dissolved3[\"geometry\"].iloc[z].buffer(8) #<---------ADJUST BUFFER SIZE HERE-------------\n",
    "                    buflist.append(buf) #Add buffers to a list\n",
    "                \n",
    "                dissolved3 = dissolved3.drop([\"index\"], axis=\"columns\") #Remove index column from dissolved3\n",
    "                bufdf[\"geometry\"] = gpd.GeoSeries(buflist) #Add contents of buflist to bufdf \n",
    "                bufdf.reset_index()\n",
    "                \n",
    "                #Create empty geodataframes to be filled with ID concerning whether buffers touch, and how they touch other buffers\n",
    "                touchingbufs = gpd.GeoDataFrame()\n",
    "                maxidissolve = gpd.GeoDataFrame()\n",
    "                \n",
    "                touchingbufslist = [] #Here we will collect the information concerning what buffers a buffer touches\n",
    "                excesslist = [] \n",
    "                \n",
    "                #Iterate over buffers. Add buffers to \"touchingbufs\" and a corresponding ID-value to touchingbufslist.\n",
    "                for v in list(range(0, len(bufdf)-1)):\n",
    "                    \n",
    "                    # FIRST, check if first feature touches another buffer or stands alone. Append touchingbufslist accordingly\n",
    "                    if len(touchingbufslist) == 0:\n",
    "                        if (bufdf.loc[v][\"geometry\"].intersects(bufdf.loc[v+1][\"geometry\"])): #Collect intersecting buffers into one df\n",
    "                            touchingbufs = touchingbufs.append(bufdf.loc[v])\n",
    "                            touchingbufslist.append(\"s\") #Create ID to identify continuous section\n",
    "                        elif (bufdf.loc[v][\"geometry\"].intersects(bufdf.loc[v+1][\"geometry\"]) == False):\n",
    "                            touchingbufs = touchingbufs.append(bufdf.loc[v])\n",
    "                            touchingbufslist.append(\"own\") #Append ID\n",
    "                    #front and back        \n",
    "                    elif (bufdf.loc[v][\"geometry\"].intersects(bufdf.loc[v+1][\"geometry\"])) and (bufdf.loc[v][\"geometry\"].intersects(bufdf.loc[int(v-1)][\"geometry\"])): \n",
    "                            touchingbufs = touchingbufs.append(bufdf.loc[v])\n",
    "                            touchingbufslist.append(\"fb\") #Append ID\n",
    "                    #back only        \n",
    "                    elif (bufdf.loc[v][\"geometry\"].intersects(bufdf.loc[v-1][\"geometry\"])) and ((bufdf.loc[v][\"geometry\"].intersects(bufdf.loc[v+1][\"geometry\"])) == False): \n",
    "                            touchingbufs = touchingbufs.append(bufdf.loc[v])\n",
    "                            touchingbufslist.append(\"b\") #Append ID\n",
    "                    #front only        \n",
    "                    elif (bufdf.loc[v][\"geometry\"].intersects(bufdf.loc[v-1][\"geometry\"]) == False) and ((bufdf.loc[v][\"geometry\"].intersects(bufdf.loc[v+1][\"geometry\"]))): \n",
    "                            touchingbufs = touchingbufs.append(bufdf.loc[v])\n",
    "                            touchingbufslist.append(\"s\") #Append ID\n",
    "                    #unconnected        \n",
    "                    elif (bufdf.loc[v][\"geometry\"].intersects(bufdf.loc[v-1][\"geometry\"]) == False) and ((bufdf.loc[v][\"geometry\"].intersects(bufdf.loc[v+1][\"geometry\"])) == False): \n",
    "                            touchingbufs = touchingbufs.append(bufdf.loc[v])\n",
    "                            touchingbufslist.append(\"own\") #Append ID\n",
    "                    #excess        \n",
    "                    elif KeyError:\n",
    "                        excesslist.append(1)\n",
    "\n",
    "\n",
    "                touchingbufs = touchingbufs.reset_index()\n",
    "                touchingbufs[\"startstop\"] = gpd.GeoSeries(touchingbufslist) #Add intersecting buffer ID to GDF which contains the buffers\n",
    "                \n",
    "                #Give running ID-Values to buffers. These will be used to dissolve continuous sections.\n",
    "                slist = []\n",
    "                idlist = []\n",
    "                for k in range(0, len(touchingbufs)):\n",
    "                    if touchingbufs[\"startstop\"].iloc[k] == \"s\":\n",
    "                        slist.append(1)\n",
    "                        idlist.append(sum(slist))\n",
    "                    elif touchingbufs[\"startstop\"].iloc[k] == \"fb\":\n",
    "                        idlist.append(sum(slist))\n",
    "                    elif touchingbufs[\"startstop\"].iloc[k] == \"b\":\n",
    "                        idlist.append(sum(slist))\n",
    "                        #slist.append(1)\n",
    "                    elif touchingbufs[\"startstop\"].iloc[k] == \"own\":\n",
    "                        slist.append(1)\n",
    "                        idlist.append(sum(slist))\n",
    "                        test = sum(slist)\n",
    "                \n",
    "                if len(touchingbufs) > 0:\n",
    "                    touchingbufs[\"dissolve\"] = gpd.GeoDataFrame(idlist)\n",
    "                    touchingbufs[\"BufID\"] = gpd.GeoDataFrame(idlist)\n",
    "                    touchingbufs[\"BufID2\"] = gpd.GeoDataFrame(idlist)\n",
    "                    \n",
    "                    tdissolve = touchingbufs.dissolve(by=\"dissolve\") #Dissolve buffers that touch by the intersecting buffer ID\n",
    "                if len(tdissolve) > 0: #If tdissolve contains something, add it to maxidissolve GDF\n",
    "                    maxidissolve = maxidissolve.append(tdissolve)\n",
    "                               \n",
    "                # Join with previously merged sections\n",
    "                bufjoin = gpd.sjoin(dissolved3, maxidissolve, how=\"left\", op=\"within\") #Spatially join links (lines) with buffers\n",
    "                bufjoin = bufjoin.reset_index()\n",
    "                bufjoinfinal = bufjoin.dissolve(by=\"BufID\") #Dissolve by BufferID\n",
    "                bufjoinfinal = bufjoinfinal.reset_index()\n",
    "                \n",
    "\n",
    "                for n in range(0, len(bufjoin)): #Add links that were not within buffers\n",
    "                    if pd.isna(bufjoin[\"BufID2\"].loc[n]):\n",
    "                        bufjoinfinal = bufjoinfinal.append(bufjoin.iloc[n])\n",
    "                \n",
    "                for q in range(0, len(bufjoinfinal)):\n",
    "                    homogeeniset_linkit = homogeeniset_linkit.append(bufjoinfinal.iloc[q]) # append final links to main GDF\n",
    "\n",
    "            else: # Any other sections need no attention and can be passed to the main GDF\n",
    "                dissolved4 = gpd.GeoDataFrame()\n",
    "                dissolved4 = dissolved4.append(dissolved.iloc[0])\n",
    "                dissolved4[\"geometry\"].iloc[0] = merge\n",
    "                homogeeniset_linkit = homogeeniset_linkit.append(dissolved4.iloc[0])\n",
    "        \n",
    "\n",
    "homogeeniset_linkit = homogeeniset_linkit.drop([\"level_0\"], axis=\"columns\")\n",
    "homogeeniset_linkit = homogeeniset_linkit.reset_index()\n",
    "homogeeniset_linkit.crs = CRS.from_epsg(3067)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unnecessary columns\n",
    "homogeeniset_linkit = homogeeniset_linkit.drop([\"HA\", \"PA\", \"KA\", \"RA\", \"LA\", \"MP\", \"RV\", \"AUTOT\", \"pituus\", \"ID_NEW\", \"index\", \"index_right\", \"SY KAVL+RV\"], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating KVL for the continuous links:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Link identifier\n",
    "homogeeniset_linkit[\"H_ID\"] = list(range(0, len(homogeeniset_linkit)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spatial join between the continuous links we just created and the original link network\n",
    "join = gpd.sjoin(homogeeniset_linkit, network2, how=\"left\", op=\"contains\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates mean KVL for continuous links\n",
    "finaldissolve1 = join.dissolve(by='H_ID', aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldissolve1.crs = CRS.from_epsg(3067)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "671"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(finaldissolve1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A small number of links, for whatever reason, are not joined with the \"contains\" method. So we do the following to obtan KVL for these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmjohan\\.conda\\envs\\gis\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning:     You are passing non-geometry data to the GeoSeries constructor. Currently,\n",
      "    it falls back to returning a pandas Series. But in the future, we will start\n",
      "    to raise a TypeError instead.\n",
      "  \n",
      "C:\\Users\\jmjohan\\.conda\\envs\\gis\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning:     You are passing non-geometry data to the GeoSeries constructor. Currently,\n",
      "    it falls back to returning a pandas Series. But in the future, we will start\n",
      "    to raise a TypeError instead.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "katulist = list(join[\"KATU_left\"])\n",
    "\n",
    "H_ID = list(join[\"H_ID\"])\n",
    "\n",
    "katuIDdf = gpd.GeoDataFrame()\n",
    "katuIDdf[\"KATU\"] = gpd.GeoSeries(katulist)\n",
    "katuIDdf[\"H_ID\"] = gpd.GeoSeries(H_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty geodataframe to which we will add rows from finaldissolve1 that do not have KVL data\n",
    "NADF = gpd.GeoDataFrame()\n",
    "for x in range(0, len(finaldissolve1)):\n",
    "    if pd.isna(finaldissolve1[\"SY KAVL+RV\"].iloc[x]):\n",
    "        row = finaldissolve1.iloc[x]\n",
    "        NADF = NADF.append(finaldissolve1.iloc[x])\n",
    "\n",
    "# Create Link identifier\n",
    "NADF[\"H_ID\"] = list(range(0, len(NADF))) \n",
    "NADF.crs = CRS.from_epsg(3067)\n",
    "\n",
    "#Create list containing street name and KL data in the correct order. Street names and KL must be re-added as they do not \"survive\" the dissolution made earlier.\n",
    "NADFIND = list(NADF.index)\n",
    "KL_LIST = list(NADF[\"KATULUOKKA\"])\n",
    "katulist2 = []\n",
    "for a in range(0, len(NADFIND)):\n",
    "    for b in range(0, len(katuIDdf)):\n",
    "        if int(NADFIND[a]) == int(katuIDdf[\"H_ID\"].iloc[b]):\n",
    "            katulist2.append(str(katuIDdf[\"KATU\"].iloc[b]))\n",
    "            \n",
    "NADF = NADF.drop([\"index_right\"], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NADFIND_FINALDISSOLVE1 = list(finaldissolve1.index)\n",
    "katulist3 = []\n",
    "\n",
    "for c in range(0, len(NADFIND_FINALDISSOLVE1)):\n",
    "    for d in range(0, len(homogeeniset_linkit)):\n",
    "        if int(NADFIND_FINALDISSOLVE1[c]) == int(homogeeniset_linkit[\"H_ID\"].iloc[d]):\n",
    "            katulist3.append(str(homogeeniset_linkit[\"KATU\"].iloc[d]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldissolve1 = finaldissolve1.dropna(subset=['SY KAVL+RV'], axis='rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add street names to finaldissolve1\n",
    "finaldissolve1[\"KATU\"] = gpd.GeoDataFrame(katulist3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(NADF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUTOT</th>\n",
       "      <th>BufID</th>\n",
       "      <th>BufID2</th>\n",
       "      <th>HA</th>\n",
       "      <th>ID_NEW</th>\n",
       "      <th>KA</th>\n",
       "      <th>KATULUOKKA</th>\n",
       "      <th>KL_left</th>\n",
       "      <th>KL_right</th>\n",
       "      <th>LA</th>\n",
       "      <th>...</th>\n",
       "      <th>PA</th>\n",
       "      <th>RA</th>\n",
       "      <th>RV</th>\n",
       "      <th>SY KAVL+RV</th>\n",
       "      <th>geometry</th>\n",
       "      <th>level_0</th>\n",
       "      <th>linkki_left</th>\n",
       "      <th>linkki_right</th>\n",
       "      <th>pituus</th>\n",
       "      <th>H_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MULTILINESTRING Z ((393438.149 6678276.082 0.0...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2656.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINESTRING Z (393526.397 6678111.065 0.000, 39...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2656.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MULTILINESTRING Z ((386375.291 6680364.899 0.0...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>747.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MULTILINESTRING Z ((386372.685 6680342.888 0.0...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>747.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MULTILINESTRING Z ((386428.785 6680379.524 0.0...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>747.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AUTOT  BufID  BufID2  HA  ID_NEW  KA  KATULUOKKA  KL_left  KL_right  LA  \\\n",
       "20    NaN    1.0     1.0 NaN     NaN NaN         3.0      3.0       NaN NaN   \n",
       "21    NaN    NaN     NaN NaN     NaN NaN         3.0      3.0       NaN NaN   \n",
       "35    NaN   14.0    14.0 NaN     NaN NaN         6.0      6.0       NaN NaN   \n",
       "37    NaN   16.0    16.0 NaN     NaN NaN         6.0      6.0       NaN NaN   \n",
       "38    NaN   17.0    17.0 NaN     NaN NaN         6.0      6.0       NaN NaN   \n",
       "\n",
       "    ...  PA  RA  RV  SY KAVL+RV  \\\n",
       "20  ... NaN NaN NaN         NaN   \n",
       "21  ... NaN NaN NaN         NaN   \n",
       "35  ... NaN NaN NaN         NaN   \n",
       "37  ... NaN NaN NaN         NaN   \n",
       "38  ... NaN NaN NaN         NaN   \n",
       "\n",
       "                                             geometry  level_0  linkki_left  \\\n",
       "20  MULTILINESTRING Z ((393438.149 6678276.082 0.0...      0.0       2656.0   \n",
       "21  LINESTRING Z (393526.397 6678111.065 0.000, 39...      3.0       2656.0   \n",
       "35  MULTILINESTRING Z ((386375.291 6680364.899 0.0...     13.0        747.0   \n",
       "37  MULTILINESTRING Z ((386372.685 6680342.888 0.0...     15.0        747.0   \n",
       "38  MULTILINESTRING Z ((386428.785 6680379.524 0.0...     16.0        747.0   \n",
       "\n",
       "   linkki_right  pituus  H_ID  \n",
       "20          NaN     NaN     0  \n",
       "21          NaN     NaN     1  \n",
       "35          NaN     NaN     2  \n",
       "37          NaN     NaN     3  \n",
       "38          NaN     NaN     4  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NADF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find KVL information for links where joining failed. Some may still be unconnected. Currently unsure how to fix, but the number of these links appears very small. 9.6.2020\n",
    "nulljoin = gpd.sjoin(NADF, network2, how=\"left\", op=\"within\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nulljoin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulldissolve = nulljoin.dissolve(by='H_ID', aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulldissolve = nulldissolve.drop([\n",
    " 'AUTOT_left',\n",
    " 'HA_left',\n",
    " 'ID_NEW_left',\n",
    " 'KA_left',\n",
    " 'KATULUOKKA',\n",
    " 'KL_left',\n",
    " 'KL_right',\n",
    " 'LA_left',\n",
    " 'LVUOSI_left',\n",
    " 'LVUOSI_right',\n",
    " 'MP_left',\n",
    " 'PA_left',\n",
    " 'RA_left',\n",
    " 'RV_left',\n",
    " 'SY KAVL+RV_left',\n",
    " 'linkki_left',\n",
    " 'linkki_right',\n",
    " 'pituus_left',], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmjohan\\.conda\\envs\\gis\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning:     You are passing non-geometry data to the GeoSeries constructor. Currently,\n",
      "    it falls back to returning a pandas Series. But in the future, we will start\n",
      "    to raise a TypeError instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\jmjohan\\.conda\\envs\\gis\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning:     You are passing non-geometry data to the GeoSeries constructor. Currently,\n",
      "    it falls back to returning a pandas Series. But in the future, we will start\n",
      "    to raise a TypeError instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "nulldissolve[\"KATULUOKKA\"] = gpd.GeoSeries(KL_LIST)\n",
    "nulldissolve[\"KATU\"] = gpd.GeoSeries(katulist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldissolve1 = finaldissolve1[['geometry', 'KATU', 'KATULUOKKA', 'HA', 'PA', 'KA', 'RA', 'LA', 'MP', 'RV', 'AUTOT', 'SY KAVL+RV']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulldissolve = nulldissolve[['geometry', 'HA_right', 'PA_right', 'KA_right', 'RA_right', 'LA_right', 'MP_right', 'RV_right', 'AUTOT_right', 'SY KAVL+RV_right', 'KATU', 'KATULUOKKA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = {'HA_right': 'HA', 'PA_right': 'PA', 'KA_right': 'KA', 'RA_right': 'RA', 'LA_right': 'LA',\n",
    "       'MP_right': 'MP', 'RV_right': 'RV', 'AUTOT_right': 'AUTOT', 'SY KAVL+RV_right': 'SY KAVL+RV'}\n",
    "\n",
    "nulldissolve = nulldissolve.rename(columns=new_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['geometry', 'HA', 'PA', 'KA', 'RA', 'LA', 'MP', 'RV', 'AUTOT',\n",
       "       'SY KAVL+RV', 'KATU', 'KATULUOKKA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulldissolve.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalproduct = finaldissolve1\n",
    "finalproduct = finalproduct.append(nulldissolve)\n",
    "finalproduct = finalproduct.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmjohan\\.conda\\envs\\gis\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning:     You are passing non-geometry data to the GeoSeries constructor. Currently,\n",
      "    it falls back to returning a pandas Series. But in the future, we will start\n",
      "    to raise a TypeError instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "finalproduct[\"ID\"] = gpd.GeoSeries(list(range(0, len(finalproduct))))\n",
    "finalproduct = finalproduct.drop([\"H_ID\"], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalproduct[\"pituus\"] = finalproduct.geometry.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalproduct.crs = CRS.from_epsg(3067)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "homogeeniset_linkit.crs = CRS.from_epsg(3067)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldissolve1.crs = CRS.from_epsg(3067)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulldissolve.crs = CRS.from_epsg(3067)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalproduct.to_file(\"C:/data/L3Pilot/Katuverkko/Helsinki/hki_link_liikennemääräkartta2019/finalproduct4.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finalproduct.to_csv(\"C:/data/L3Pilot/Katuverkko/Helsinki/hki_link_liikennemääräkartta2019/finalproduct.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nulldissolve.to_csv(\"C:/data/L3Pilot/Katuverkko/Helsinki/hki_link_liikennemääräkartta2019/nulldissolve.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finaldissolve1.to_file(\"C:/data/L3Pilot/Katuverkko/Helsinki/hki_link_liikennemääräkartta2019/finaldissolve.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finaldissolve1.to_csv(\"C:/data/L3Pilot/Katuverkko/Helsinki/hki_link_liikennemääräkartta2019/finaldissolve.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nulldissolve.to_file(\"C:/data/L3Pilot/Katuverkko/Helsinki/hki_link_liikennemääräkartta2019/nulldissolve2.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#homogeeniset_linkit.to_file(\"C:/data/L3Pilot/Katuverkko/Helsinki/hki_link_liikennemääräkartta2019/homogeeniset_linkit_mergetest_connectionsfixed.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#homogeeniset_linkit.to_csv(\"C:/data/L3Pilot/Katuverkko/Helsinki/hki_link_liikennemääräkartta2019/homogeeniset_linkit_mergetest_connectionsfixed.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
